import tensorflow as tf
import matplotlib.pyplot as plt
# Load the training dataset
train_dataset_path = r'C:\Users\hari\Downloads\archive (1)\train'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train_dataset_path,
    image_size=(48, 48),
    batch_size=32)

# Load the testing dataset
test_dataset_path = r'C:\Users\hari\Downloads\archive (1)\test'
test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    test_dataset_path,
    image_size=(48, 48),
    batch_size=32)

# Display class names
class_names = train_dataset.class_names
print("Class names:", class_names)

# Visualize some training images
plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(class_names[labels[i]])
        plt.axis("off")
plt.show()

# Preprocessing function to normalize images
def preprocess(image, label):
    return tf.cast(image, tf.float32) / 255.0, label

# Apply the preprocessing function
train_dataset = train_dataset.map(preprocess)
test_dataset = test_dataset.map(preprocess)

# Configure the datasets for performance
AUTOTUNE = tf.data.experimental.AUTOTUNE
train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)

# Building the CNN Model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(48, 48, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(class_names), activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
history = model.fit(train_dataset, epochs=3, validation_data=test_dataset)
# Evaluate the model on the test dataset
test_loss, test_acc = model.evaluate(test_dataset)
print("\nTest accuracy:", test_acc)
# Plot training and validation accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(range(3), acc, label='Training Accuracy')
plt.plot(range(3), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.subplot(1, 2, 2)
plt.plot(range(3), loss, label='Training Loss')
plt.plot(range(3), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
